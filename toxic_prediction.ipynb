{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "toxic_Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXltxyFCHI9J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import copy\n",
        "import math\n",
        "import csv\n",
        "from google.colab import files\n",
        "from collections import deque\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4-kPpCX3xEd",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "outputId": "585602bc-85e8-4c8a-948b-6d3696821fa9"
      },
      "source": [
        "uploaded = files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6b673d90-4adc-4738-a4ac-5580ab119146\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6b673d90-4adc-4738-a4ac-5580ab119146\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving hERG_Sample_Discrete_Dataset.csv to hERG_Sample_Discrete_Dataset.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4J-Tu4d39G0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_data   = \"hERG_Sample_Discrete_Dataset.csv\"\n",
        "handle_file = open(file_data, \"r\")\n",
        "data        = handle_file.readlines()\n",
        "handle_file.close()\n",
        "\n",
        "size_row    = 2245    # 각 데이터의 요소\n",
        "size_col    = 6095    # 데이터 갯수\n",
        "\n",
        "num_image   = len(data)   #10000개\n",
        "count       = 0     # count for the number of images\n",
        "\n",
        "#\n",
        "# normalize the values of the input data to be [0, 1]\n",
        "#\n",
        "def normalize(data):\n",
        "\n",
        "    data_normalized = (data - min(data)) / (max(data) - min(data))\n",
        "\n",
        "    return(data_normalized)\n",
        "\n",
        "\n",
        "#\n",
        "# make a matrix each column of which represents an images in a vector form\n",
        "#\n",
        "X = np.empty((6095, 2245))\n",
        "label = np.empty(6095)\n",
        "\n",
        "for line in data:\n",
        "  if count == 0:\n",
        "    count += 1\n",
        "    continue\n",
        "  else:  \n",
        "    line_data   = line.split(',')\n",
        "    #print(len(line_data))\n",
        "    data_label  = line_data[2246]\n",
        "    #print(data_label)\n",
        "    data_vector = np.asfarray(line_data[1:2246])\n",
        "    #print(len(data_vector))\n",
        "    #print(data_vector)\n",
        "    data_vector = normalize(data_vector)\n",
        "\n",
        "    label[count-1] = data_label       # size : 10000\n",
        "    X[count-1, :]    = data_vector   # size : 6095 * 2245\n",
        "\n",
        "    count += 1\n",
        "\n",
        "X = torch.from_numpy(X)\n",
        "X = X.type(torch.float32)\n",
        "label = torch.from_numpy(label)\n",
        "label = label.type(torch.float32)         #float32 지정을 통해 backward 오류 해결!\n",
        "\n",
        "train_costs = deque()\n",
        "test_costs = deque()\n",
        "iters = deque()\n",
        "train_accuracys = deque()\n",
        "test_accuracys = deque()"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqV5G-wx82E1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "598435e6-d895-481c-8bfa-812897757d48"
      },
      "source": [
        "print(X[6094])\n",
        "print(label[6094])"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.0267, 0.0009, 0.0027,  ..., 0.0040, 0.0348, 0.0147])\n",
            "tensor(0.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kwsSUS19rps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NeuralNet(torch.nn.Module):\n",
        "  def __init__(self, D_in, H, D_out):\n",
        "    super(NeuralNet, self).__init__()\n",
        "    self.linear1 = nn.Linear(D_in, H)\n",
        "    self.linear2 = nn.Linear(H, D_out)\n",
        "\n",
        "  def forward(self, x):\n",
        "    h_relu = self.linear1(x).clamp(min=0)\n",
        "    y_pred = self.linear2(h_relu)\n",
        "    return y_pred"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjmgL6_k-7Vl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f78f9d93-fead-4b6d-c2a4-89d0061110b8"
      },
      "source": [
        "def main():\n",
        "  D_in, H, D_out = 2245, 40, 1\n",
        "  model = NeuralNet(D_in, H, D_out)\n",
        "\n",
        "  criterion = nn.MSELoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "  \n",
        "  for iter in range(500):\n",
        "      y_pred = model(X.float())  \n",
        "      optimizer.zero_grad()\n",
        "      loss = criterion(y_pred, label)\n",
        "      #print(loss)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:432: UserWarning: Using a target size (torch.Size([6095])) that is different to the input size (torch.Size([6095, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(0.5690, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5679, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5665, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5652, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5641, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5627, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5615, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5608, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5602, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5596, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5587, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5576, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5564, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5551, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5536, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5526, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5514, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5507, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5502, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5497, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5491, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5486, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5481, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5477, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5472, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5467, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5461, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5455, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5447, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5439, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5430, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5420, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5410, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5398, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5389, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5378, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5367, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5356, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5348, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5339, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5331, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5323, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5315, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5306, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5296, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5287, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5278, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5269, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5260, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5250, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5240, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5231, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5223, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5214, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5206, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5197, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5188, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5179, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5171, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5162, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5153, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5146, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5139, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5132, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5125, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5118, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5111, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5104, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5096, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5089, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5082, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5075, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5068, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5059, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5050, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5041, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5032, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5023, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5014, grad_fn=<MseLossBackward>)\n",
            "tensor(0.5004, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4995, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4987, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4977, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4968, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4959, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4949, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4940, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4932, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4924, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4916, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4910, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4902, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4894, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4887, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4878, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4870, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4861, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4852, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4844, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4836, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4826, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4817, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4810, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4801, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4793, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4784, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4776, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4767, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4759, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4752, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4744, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4737, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4729, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4722, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4714, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4705, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4697, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4689, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4681, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4673, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4664, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4655, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4647, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4640, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4632, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4623, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4614, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4606, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4600, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4592, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4584, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4576, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4569, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4561, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4554, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4547, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4540, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4533, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4526, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4519, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4512, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4504, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4497, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4490, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4483, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4476, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4468, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4461, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4452, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4444, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4436, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4427, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4419, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4411, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4403, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4395, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4386, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4378, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4369, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4361, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4353, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4344, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4336, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4328, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4320, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4311, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4303, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4294, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4284, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4275, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4266, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4258, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4250, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4241, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4232, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4223, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4215, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4207, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4198, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4190, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4181, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4173, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4165, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4156, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4148, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4139, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4129, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4120, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4111, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4103, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4095, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4087, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4078, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4070, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4061, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4053, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4045, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4036, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4028, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4019, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4012, grad_fn=<MseLossBackward>)\n",
            "tensor(0.4003, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3996, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3988, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3980, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3972, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3964, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3956, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3949, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3941, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3933, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3925, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3917, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3908, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3900, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3892, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3884, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3876, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3869, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3861, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3855, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3847, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3839, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3832, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3825, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3817, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3810, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3803, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3796, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3789, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3781, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3774, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3766, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3759, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3752, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3745, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3737, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3730, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3722, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3715, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3707, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3701, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3695, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3687, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3680, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3672, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3665, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3659, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3652, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3644, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3637, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3629, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3623, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3617, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3610, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3602, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3595, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3587, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3581, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3574, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3566, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3560, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3554, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3548, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3540, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3533, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3526, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3519, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3512, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3507, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3500, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3492, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3486, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3479, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3472, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3465, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3458, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3451, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3444, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3438, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3431, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3425, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3418, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3411, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3405, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3400, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3393, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3387, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3382, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3376, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3370, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3365, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3358, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3352, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3346, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3341, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3335, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3328, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3322, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3315, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3310, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3304, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3298, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3293, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3287, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3281, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3275, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3269, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3264, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3258, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3253, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3247, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3243, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3237, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3232, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3226, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3221, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3215, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3210, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3204, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3198, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3194, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3188, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3183, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3178, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3172, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3168, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3162, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3157, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3152, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3147, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3142, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3137, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3133, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3128, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3123, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3118, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3113, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3109, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3104, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3098, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3093, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3089, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3084, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3079, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3074, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3069, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3064, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3060, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3057, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3052, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3047, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3042, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3038, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3033, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3029, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3025, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3020, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3017, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3012, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3008, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3004, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3000, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2995, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2991, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2987, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2983, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2979, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2976, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2972, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2968, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2965, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2961, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2957, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2953, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2949, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2945, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2942, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2937, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2933, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2930, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2926, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2922, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2919, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2916, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2912, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2909, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2905, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2902, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2899, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2895, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2891, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2887, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2884, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2881, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2878, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2875, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2871, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2869, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2866, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2863, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2859, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2856, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2853, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2850, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2846, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2844, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2841, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2838, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2835, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2832, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2829, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2826, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2822, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2819, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2816, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2814, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2811, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2808, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2806, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2803, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2800, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2797, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2794, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2792, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2790, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2787, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2785, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2782, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2780, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2778, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2776, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2774, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2771, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2769, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2766, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2764, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2761, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2760, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2757, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2755, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2752, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2750, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2747, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2745, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2743, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2741, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2739, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2737, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2735, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2732, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2730, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2728, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2726, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2724, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2722, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2720, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2718, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2716, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2714, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2713, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2711, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2709, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2707, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2705, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2703, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2701, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2700, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2698, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2696, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2694, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2693, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2691, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2689, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2688, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2686, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2685, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2683, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2681, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2680, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2678, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2677, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2675, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2673, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2672, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2671, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2669, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2668, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2666, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2665, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2664, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2662, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2661, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2659, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2658, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2657, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2656, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2654, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2653, grad_fn=<MseLossBackward>)\n",
            "tensor(0.2651, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
